# Random Forest

```{r}
load("spam.RData")
data <- spam
head(data)
head(spam)
```

# Classification tree on spam data
```{r}
library(rpart)

cart.tree = rpart(spam~., 
                  data=spam,  
                  method="class", cp=0.005) #method="class" for a classification tree; method="anova" for a regression tree
plot(cart.tree, margin=0.04)
text(cart.tree)
# tree pruning --> make the tree structure simple
plotcp(cart.tree)
cart.tree.2 = prune(cart.tree, cp=0.008)
plot(cart.tree.2, margin=0.04)
text(cart.tree.2)
```

# RF on spam data
```{r}
# training
library(randomForest) # this is the Random Forests package we need
fit = randomForest(spam~., spam, ntree=100, do.trace=5)
# build a RF with 1000 trees; report the results every 100 trees.



# training
fit = randomForest(spam~.,spam,ntree=200,do.trace=50,
	importance=TRUE, confusion=TRUE)
fit$importance # generate the variable importance ranking table
varImpPlot(fit) # generate the variable importance ranking plot
fit$confusion # generate the confusion matrix 
```

# RF on housing.data
```{r}
data = read.csv("housing.csv", stringsAsFactors=FALSE, header=TRUE)
data[,10] = as.factor(data[,10])

# random forest
library(randomForest)
# Caution: it takes 10-20mins to generate the results
fit = randomForest(median_house_value~.,
			data,ntree=500,do.trace=50,na.action=na.omit,importance=TRUE,
			proximity=TRUE)
save(fit, file="house_fit.RData") # I ran it before the lecture and save the output
load("house_fit.RData") # this is how you could load the output previouly saved


# mse over # trees
plot((c(1:500)), fit$mse, col="blue",xlab="# trees grown", ylab="mse")

# variable importance
varImpPlot(fit)

# proximity:
case = sample(1:nrow(data),1000) # to make the calculation faster; I randomly sampled 1000 rows from the original data
fit.2 = randomForest(median_house_value~.,
			data[case,],ntree=500,do.trace=50,na.action=na.omit,importance=TRUE,
			proximity=TRUE)
proxi = fit.2$proximity
plot(proxi[100,],type="h",ylab="proximity",xlab="data points",col="blue")

dim(proxi)
```

# PCA
```{r}
for (i in 1:ncol(proxi)){
  proxi[,i]=(proxi[,i]-mean(proxi[,i]))/sqrt(var(proxi[,i]))
}
pr.out = prcomp(proxi, scale=FALSE)

library(rgl) # package for 3D visualization
plotPCA <- function(x, nGroup, text) {  # user-defined function
    n <- ncol(x) 
    if(!(n %in% c(2,3))) { # check if 2d or 3d
        stop("x must have either 2 or 3 columns")
    }

    fit <- hclust(dist(x), method="complete") # cluster
    groups <- cutree(fit, k=nGroup)

    if(n == 3) { # 3d plot
        plot3d(x, col="green", type="s", size=1, axes=F)
        axes3d(edges=c("x--", "y--", "z"), lwd=3, axes.len=2, labels=FALSE)
        text3d(x,texts=text)
        grid3d("x")
        grid3d("y")
        grid3d("z")
    } else { # 2d plot
        maxes <- apply(abs(x), 2, max)
        rangeX <- c(-maxes[1], maxes[1])
        rangeY <- c(-maxes[2], maxes[2])
        plot(x, col=groups, pch=19, xlab=colnames(x)[1], ylab=colnames(x)[2], xlim=rangeX, ylim=rangeY)
        lines(c(0,0), rangeX*2)
        lines(rangeY*2, c(0,0))
    }
}
plotPCA(pr.out$x[,1:3],1,text=rownames(data[case,]))
```